{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B Run: https://app.wandb.ai/univai-ss2019/CaptionHack/runs/gl5qv1br\n",
      "Call `%%wandb` in the cell containing your training loop to display live results.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding, LSTM, CuDNNLSTM\n",
    "from keras.layers import Conv1D, Flatten\n",
    "from keras.datasets import imdb\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "import numpy as np\n",
    "from keras.preprocessing import text\n",
    "\n",
    "wandb.init()\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import __version__\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = \"../flickr/Flickr_8k.trainImages.txt\"\n",
    "val_txt = \"../flickr/Flickr_8k.devImages.txt\"\n",
    "test_txt = \"../flickr/Flickr_8k.testImages.txt\"\n",
    "token_txt = \"../flickr/Flickr8k.token.txt\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../flickr/datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions = [e.strip().split(\"\\t\") for e in open(token_txt).readlines()]\n",
    "trainfiles = [e.strip() for e in open(train_txt).readlines()]\n",
    "devfiles = [e.strip() for e in open(val_txt).readlines()]\n",
    "testfiles = [e.strip() for e in open(test_txt).readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1000268201_693b08cb0e.jpg#0',\n",
       "  'A child in a pink dress is climbing up a set of stairs in an entry way .'],\n",
       " '2513260012_03d33305cf.jpg',\n",
       " '2090545563_a4e66ec76b.jpg',\n",
       " '3385593926_d3e9c21170.jpg')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions[0], trainfiles[0], devfiles[0], testfiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "# generator = datagen.flow_from_directory(\n",
    "#         data_dir, class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "captiondict = defaultdict(list)\n",
    "for pair in captions:\n",
    "    image = pair[0].split('#')[0]\n",
    "    caption = pair[1]\n",
    "    captiondict[image].append(caption)\n",
    "traindict = {}\n",
    "devdict = {}\n",
    "testdict = {}\n",
    "for f in trainfiles:\n",
    "    traindict[f] = captiondict[f]\n",
    "for f in devfiles:\n",
    "    devdict[f] = captiondict[f]\n",
    "for f in testfiles:\n",
    "    testdict[f] = captiondict[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train = [captiondict[f] for f in trainfiles]\n",
    "captions_valid = [captiondict[f] for f in devfiles]\n",
    "captions_test = [captiondict[f] for f in testfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  itertools import chain\n",
    "train_list = list(chain.from_iterable(traindict.values()))\n",
    "validation_list = list(chain.from_iterable(devdict.values()))\n",
    "test_list = list(chain.from_iterable(testdict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_list)\n",
    "X_train = tokenizer.texts_to_sequences(train_list)\n",
    "X_valid = tokenizer.texts_to_sequences(validation_list)\n",
    "X_test = tokenizer.texts_to_sequences(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(tokenizer.word_index) +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word_dict = tokenizer.index_word\n",
    "word_index_dict = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = []\n",
    "next_word = []\n",
    "for list_t in X_train:\n",
    "    for i in range(1,len(list_t)):\n",
    "        word.append(list_t[i-1])\n",
    "        next_word.append(list_t[i])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_val = []\n",
    "next_word_val = []\n",
    "for list_t in X_valid:\n",
    "    for i in range(1,len(list_t)):\n",
    "        word_val.append(list_t[i-1])\n",
    "        next_word_val.append(list_t[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294479, 294479)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word), len(next_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48962, 48962)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_val), len(next_word_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7371, 7376)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(next_word_val), num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f= to_categorical(word, num_classes= num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_f = to_categorical(next_word, num_classes = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_f = to_categorical(word_val, num_classes= num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_f = to_categorical(next_word_val, num_classes= num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294479, 7376)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294479"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/externals/joblib/_multiprocessing_helpers.py:38: UserWarning: [Errno 12] Cannot allocate memory.  joblib will operate in serial mode\n",
      "  warnings.warn('%s.  joblib will operate in serial mode' % (e,))\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(num_classes, 50, input_length = len(word)))\n",
    "model.add(CuDNNLSTM(50))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_f, y_train_f,\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          validation_data=(X_valid_f, y_valid_f), callbacks=[WandbCallback()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
